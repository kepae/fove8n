{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a010aeac",
   "metadata": {},
   "source": [
    "# Get the tensors for each frame from three videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee256e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1ccdf",
   "metadata": {},
   "source": [
    "## Get the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc485cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs50 = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c808c9",
   "metadata": {},
   "source": [
    "## Keep only the first layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80eb05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the first layers of net\n",
    "modules=list(rs50.children())[:4]\n",
    "convNet = nn.Sequential(*modules)\n",
    "\n",
    "# fix the parameters\n",
    "for p in convNet.parameters():\n",
    "    p.requires_grad=False\n",
    "\n",
    "# keep just the first layer \n",
    "mods=list(rs50.children())[:1]\n",
    "conv = nn.Sequential(*mods)\n",
    "\n",
    "# fix the parameters\n",
    "for p in conv.parameters():\n",
    "    p.requires_grad=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f8ce0",
   "metadata": {},
   "source": [
    "## Get Image Features\n",
    "\n",
    "The output is a 64 channel tensor ( x W x H) that can be sent to our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d640c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "def image_loader(imgName):\n",
    "    im = Image.open(imgName)\n",
    "    im = transform(im)\n",
    "    im = torch.unsqueeze(im,0)\n",
    "    return im#.cuda()\n",
    "\n",
    "fDir = '/mindhive/nklab5/users/hlk/projects/vidDNN/threeVids/origFrames/'\n",
    "tDir = '/mindhive/nklab5/users/hlk/projects/vidDNN/threeVids/preProc/tripping/fTensors/'\n",
    "vids = ['tripping240','tripping339','tripping432']                        \n",
    "\n",
    "for v in vids:\n",
    "    vDir = fDir + v\n",
    "    fs = os.listdir(vDir)\n",
    "    for f in fs:\n",
    "        imPath = vDir + '/' + f\n",
    "        im = image_loader(imPath)\n",
    "        tens = conv(im)\n",
    "        tensPath = tDir + v + '/tns' + f[1:5] + '.pt' \n",
    "        torch.save(tens,tensPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
