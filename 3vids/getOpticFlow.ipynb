{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4dea21",
   "metadata": {},
   "source": [
    "# Optic Flow \n",
    "\n",
    "Get the optic flow from each frame for three videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519e36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('core')\n",
    "sys.path.append('/mindhive/nklab5/users/hlk/packages/RAFT/core/')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from raft import RAFT\n",
    "from utils import flow_viz\n",
    "from utils.utils import InputPadder\n",
    "\n",
    "from argparse import Namespace\n",
    "from utils import flow_viz\n",
    "from utils import frame_utils\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810cc917",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "load and view images and optic flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65d933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(imfile):\n",
    "    img = np.array(Image.open(imfile)).astype(np.uint8)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    return img[None].to(DEVICE)\n",
    "\n",
    "\n",
    "def viz(img, flo):\n",
    "    img = img[0].permute(1,2,0).cpu().numpy()\n",
    "    flo = flo[0].permute(1,2,0).cpu().numpy()\n",
    "    \n",
    "    # map flow to rgb image\n",
    "    flo = flow_viz.flow_to_image(flo)\n",
    "    img_flo = np.concatenate([img, flo], axis=0)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(img_flo / 255.0)\n",
    "    #plt.imshow(flo)\n",
    "    plt.axis('off')  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca4a96",
   "metadata": {},
   "source": [
    "Extract Optic flow for images using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d92cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optic_flow(vDir,flowDir,mPath):\n",
    "    # set the parameters for the model\n",
    "    args = Namespace(alternate_corr=False, mixed_precision=False, model=mPath, path=vDir, small=False)\n",
    "    model = torch.nn.DataParallel(RAFT(args))\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "    model = model.module\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    # use the pre-trained model\n",
    "    with torch.no_grad():\n",
    "        # get all of the frame names\n",
    "        images = glob.glob(os.path.join(args.path, '*.png')) + \\\n",
    "                     glob.glob(os.path.join(args.path, '*.jpg'))\n",
    "        images = sorted(images)\n",
    "        frame = 1\n",
    "        for imfile1, imfile2 in zip(images[:-1], images[1:]):\n",
    "            image1 = load_image(imfile1)\n",
    "            image2 = load_image(imfile2)\n",
    "            \n",
    "            # pad the images\n",
    "            padder = InputPadder(image1.shape)\n",
    "            image1, image2 = padder.pad(image1, image2)\n",
    "            \n",
    "            # extract the optic flow for each image\n",
    "            flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n",
    "        \n",
    "            # save the optic flow file for each frame\n",
    "            frame = frame + 1\n",
    "            flo.unpad(flow_up[0]).permute(1, 2, 0).cpu().numpy()\n",
    "            output_file = os.path.join(flowDir, 'of%04d.flo' % (frame))\n",
    "            frame_utils.writeFlow(output_file, flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275beb9",
   "metadata": {},
   "source": [
    "# Flow for Frames\n",
    "\n",
    "Get the optic flow for each of our frames in each of our three movies and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558055fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fDir = '/mindhive/nklab5/users/hlk/projects/vidDNN/threeVids/preProc/tripping/frames/'\n",
    "oDir = '/mindhive/nklab5/users/hlk/projects/vidDNN/threeVids/preProc/tripping/opticFlow/'\n",
    "mPath = '/mindhive/nklab5/users/hlk/projects/vidDNN/fove8n/learn/RAFT/models/raft-things.pth'\n",
    "vids = ['tripping240','tripping339','tripping432']                        \n",
    "\n",
    "for v in vids:\n",
    "    vDir = fDir + v\n",
    "    flowDir = oDir + v\n",
    "    get_optic_flow(vDir,flowDir,mPath)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0f61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
