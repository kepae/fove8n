{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fove8n_rnn_modeling_wip.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f6c54042e094f428d7507c3c70d9506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d86f7e6da3144e25ad4f16d55be31991",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_237fa08ab83b46de965469d76640f9ee",
              "IPY_MODEL_08ff1f300a6349309936bba78df58fdb"
            ]
          }
        },
        "d86f7e6da3144e25ad4f16d55be31991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "237fa08ab83b46de965469d76640f9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_916abb3637fd4b7d968cb59772d4fc79",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73840322d1d14c5f85d7895c0c656827"
          }
        },
        "08ff1f300a6349309936bba78df58fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70768c108b0942cb9b49e8d23cb89e95",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:16&lt;00:00, 6.33MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dff93888806450aa7b761dc5355e3bb"
          }
        },
        "916abb3637fd4b7d968cb59772d4fc79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73840322d1d14c5f85d7895c0c656827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70768c108b0942cb9b49e8d23cb89e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dff93888806450aa7b761dc5355e3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZJFfE6kfeJY",
        "outputId": "47063006-9e62-419d-d802-a26c3d24e2b1"
      },
      "source": [
        "!pip install icecream"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: icecream in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.6.0)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.4.4)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMIg5Hlmg4HM",
        "outputId": "5af945e3-0b8c-429d-e1e5-062d3ca7e117"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from icecream import ic  # better than print()\n",
        "\n",
        "# Set a random seed for predictable behavior\n",
        "torch.manual_seed(6862)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4db4fabbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "3f6c54042e094f428d7507c3c70d9506",
            "d86f7e6da3144e25ad4f16d55be31991",
            "237fa08ab83b46de965469d76640f9ee",
            "08ff1f300a6349309936bba78df58fdb",
            "916abb3637fd4b7d968cb59772d4fc79",
            "73840322d1d14c5f85d7895c0c656827",
            "70768c108b0942cb9b49e8d23cb89e95",
            "3dff93888806450aa7b761dc5355e3bb"
          ]
        },
        "id": "1k-cf0pg7rsY",
        "outputId": "bf82d4aa-9769-4c3d-d940-86585f7e7c71"
      },
      "source": [
        "# Returns a copy of the model but without the last layer, according to model.children().\n",
        "def strip_last_layer(model):\n",
        "    return torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "\n",
        "resnet50_pretrained = torchvision.models.resnet50(pretrained=True, progress=True)\n",
        "# print(strip_last_layer(resnet18_pretrained))\n",
        "\n",
        "# torchsummary.summary(strip_last_layer(resnet50_pretrained), (3, 224, 224))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f6c54042e094f428d7507c3c70d9506",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFNIgriLborq",
        "outputId": "c176bf86-02fb-4e1e-8e5c-6a54495a4cf0"
      },
      "source": [
        "# Clone and Import VideoFrameDataLoader utils.\n",
        "\n",
        "if not os.path.isdir('/content/Video-Dataset-Loading-Pytorch'):\n",
        "  !git clone https://github.com/RaivoKoot/Video-Dataset-Loading-Pytorch\n",
        "\n",
        "sys.path.insert(1,'/content/Video-Dataset-Loading-Pytorch')  # don't use sys.path.append, as we might re-run repeatedly\n",
        "\n",
        "from video_dataset import VideoFrameDataset, ImglistToTensor"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Video-Dataset-Loading-Pytorch'...\n",
            "remote: Enumerating objects: 250, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (211/211), done.\u001b[K\n",
            "remote: Total 250 (delta 103), reused 144 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (250/250), 688.74 KiB | 4.72 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B-qxmEqcIa_"
      },
      "source": [
        "'''\n",
        "Download the simplest 2-class toy data, already split into frames:\n",
        "moments2classes/\n",
        "-- training/\n",
        "   |-- clapping/\n",
        "      |-- clapping1/ # video sample file\n",
        "           |-- <frame_01>.jpg\n",
        "           |-- <frame_02>.jpg\n",
        "           |-- ...\n",
        "      |-- clapping2/\n",
        "           |-- ...\n",
        "      |-- .../\n",
        "   |-- constructing/\n",
        "      |-- construction01/\n",
        "           |-- ...\n",
        "'''\n",
        "\n",
        "if not os.path.isfile('moments2classes.zip'):\n",
        "  !wget 'https://www.dropbox.com/s/6rdvj8qr2foju90/moments2classes.zip'\n",
        "\n",
        "if not os.path.isdir('moments2classes'):\n",
        "  !unzip 'moments2classes.zip'\n",
        "\n",
        "root_training_data_path = 'moments2classes/training/'\n",
        "annotations_file = 'moments2classes/annotations.txt'\n",
        "if not os.path.isfile(annotations_file):\n",
        "  f = open(annotations_file, \"w\")\n",
        "  f.write(\"clapping/clapping1 1 87 0\\n\")\n",
        "  f.write(\"clapping/clapping2 1 90 0\\n\")\n",
        "  f.write(\"constructing/constructing1 1 90 0\\n\")\n",
        "  f.write(\"constructing/constructing2 1 18 0\\n\")\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV_V_Nd1-yjE"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = `[0.485, 0.456, 0.406]` and std = `[0.229, 0.224, 0.225]`. You can use the following transform to normalize:\n",
        "```\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "```\n",
        "(source: https://pytorch.org/vision/stable/models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srU2cIHvcygw"
      },
      "source": [
        "preprocess = torchvision.transforms.Compose([\n",
        "    ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
        "    transforms.Resize(256),  # image batch, resize smaller edge to 299\n",
        "    transforms.CenterCrop(224),  # image batch, center crop to square 299x299\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load single, continuous tensors without any temporal sampling.\n",
        "# i.e. load all frames\n",
        "dataset = VideoFrameDataset(\n",
        "    root_path=root_training_data_path,\n",
        "    annotationfile_path=annotations_file,\n",
        "    num_segments=1,\n",
        "    frames_per_segment=18,  # SMALLEST AMOUNT OF FRAMES IN A SAMPLE\n",
        "    imagefile_template='f{:04d}.jpg',  # 4 digits in our naming convention here\n",
        "    transform=preprocess,\n",
        "    random_shift=False,\n",
        "    test_mode=False\n",
        ")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=2,  # max suggested by runtime\n",
        "    pin_memory=True\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS0wN_U0dqTb",
        "outputId": "7757f18c-8849-4f1b-bca8-d4c3a9905a61"
      },
      "source": [
        "# Each processed video tensor has shape (BATCH, FRAMES, C, W, H)\n",
        "for video_batch, labels in dataloader:\n",
        "    print(\"Labels:\", labels)\n",
        "    print(\"Video Batch Tensor Size:\", video_batch.size())\n",
        "    print(\"Batch Labels Size:\", labels.size())\n",
        "    print(\"\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels: tensor([0, 0])\n",
            "Video Batch Tensor Size: torch.Size([2, 18, 3, 224, 224])\n",
            "Batch Labels Size: torch.Size([2])\n",
            "\n",
            "Labels: tensor([0, 0])\n",
            "Video Batch Tensor Size: torch.Size([2, 18, 3, 224, 224])\n",
            "Batch Labels Size: torch.Size([2])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgrPOQbXdbJu"
      },
      "source": [
        "def plot_video(rows, cols, frame_list, plot_width, plot_height):\n",
        "    fig = plt.figure(figsize=(plot_width, plot_height))\n",
        "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                     nrows_ncols=(rows, cols),  # creates 2x2 grid of axes\n",
        "                     axes_pad=0.3,  # pad between axes in inch.\n",
        "                     )\n",
        "\n",
        "    for index, (ax, im) in enumerate(zip(grid, frame_list)):\n",
        "        # Iterating over the grid returns the Axes.\n",
        "        ax.imshow(im)\n",
        "        ax.set_title(index)\n",
        "    plt.show()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl0ANUdDl6GD"
      },
      "source": [
        "class MyRNN(nn.Module):\n",
        "    '''\n",
        "    gru_hidden_size: ???\n",
        "    '''\n",
        "    # \n",
        "    def __init__(self, gru_hidden_size, device=\"cpu\"):\n",
        "        super(MyRNN, self).__init__()\n",
        "        \n",
        "        self.gru_hidden_size = gru_hidden_size\n",
        "\n",
        "        # Use pre-trained ResNet50 model, stripped of the last fully-connected\n",
        "        # classification layer.\n",
        "        self.cnn_pretrained = strip_last_layer(torchvision.models.resnet50(pretrained=True)).cuda()\n",
        "        # Indicate that no training is needed.\n",
        "        for p in self.cnn_pretrained.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # Found by: torchsummary.summary(strip_last_layer(resnet50_pretrained), (3, 224, 224))\n",
        "        self.cnn_pretrained_out_feature_size = 2048\n",
        "\n",
        "        # TODO: Use GRU that takes prior output (not just hidden state) as next input.\n",
        "        # That is, directly concatenate the 'y' output to the next 'x' input,\n",
        "        # rather than just relying on the GRU's inner hidden state.\n",
        "        # Use out-of-the-box GRU for now.\n",
        "        self.gru = nn.GRU(input_size=self.cnn_pretrained_out_feature_size,\n",
        "                          hidden_size=gru_hidden_size, num_layers=1, bias=True,\n",
        "                          batch_first=True, dropout=0, bidirectional=False)\n",
        "        \n",
        "        '''\n",
        "        # Layer between the convolutional layer and GRU, which takes the\n",
        "        # convolutional features PLUS the GRU output features as input,\n",
        "        # and returns the same size. The purpose is to \"learn\" the importance of\n",
        "        # features from the CNN and the GRU.\n",
        "        # Consider this a pre-processing of the GRU input.\n",
        "        self.fc_combine = nn.Linear(in_features=2048 + output_size, out_features=2048 + output_size, bias=True)\n",
        "\n",
        "        # GRU cell that will be looped over. We need to loop over a cell manually\n",
        "        # (rather than a nn.GRU module that takes a whole sequence) so that we\n",
        "        # can concatenate the output from each GRU cell to the input of the next.\n",
        "        # input_size: output of a convolution of a frame (2048), plus the output.\n",
        "        self.gru = nn.GRUCell(input_size=2048 + output_size, hidden_size=gru_hidden_size, bias=True)\n",
        "        '''\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.to(device)\n",
        "        ic(input.size())\n",
        "        batch_size, frames, C, H, W = input.size()\n",
        "\n",
        "        # The CNN expects (BATCH x C x H x W). Re-size our batched video frames\n",
        "        # as one sequence just for the CNN's per-batch sample operations...\n",
        "        cnn_input = input.view(batch_size * frames, C, H, W)\n",
        "        ic(cnn_input.size())\n",
        "        cnn_output = self.cnn_pretrained(cnn_input)\n",
        "        # [BATCH * FRAMES, 2048, 1, 1]\n",
        "        ic(cnn_output.size())\n",
        "\n",
        "        # ... Then return them to our batched frames.\n",
        "        # WARNING: Very big possibility I'm fucking up the matrix shapes.\n",
        "        # batch_first=True -> (batch, seq_len, feature_size)\n",
        "        gru_input = cnn_output.view(batch_size, frames, self.cnn_pretrained_out_feature_size)\n",
        "        ic(gru_input.size())\n",
        "\n",
        "        # Run feature vectors (one per frame per batch sample) through GRU.\n",
        "        gru_output, h_n = self.gru(gru_input)\n",
        "        # batch_first=True -> [BATCH, FRAMES, HIDDEN_SIZE]\n",
        "        ic(gru_output.size())\n",
        "        # [1, BATCH, HIDDEN_SIZE] (ignores batch_first and is shared across batches!)\n",
        "        ic(h_n.size())\n",
        "\n",
        "        return gru_output\n",
        "\n",
        "        # TODO: code for the custom GRU cell\n",
        "        '''\n",
        "        output = torch.tensor([])\n",
        "        output = output.to(input.get_device())\n",
        "        h_0 = self.initHidden()\n",
        "        last_gru_out = self.initHidden()\n",
        "\n",
        "        for frame in range(frames):\n",
        "            # Pre-trained CNN expects one frame at a time\n",
        "            cnn_out = self.cnn(input[:, f, :, :, :]).unsqueeze(0)\n",
        "            print('cnn_out: ', cnn_out.size)\n",
        "        '''\n",
        "\n",
        "    # def initHidden(self):\n",
        "    #     return torch.zeros(1, self.gru_hidden_size)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsfmXzOXd41R",
        "outputId": "4e3861ca-bc69-43e2-8e0c-5431b6f0e0e8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net = MyRNN(gru_hidden_size=3, device=device).to(device)\n",
        "# ic(net)\n",
        "\n",
        "# Each processed video tensor has shape (BATCH x FRAMES x CHANNELS x HEIGHT x WIDTH)\n",
        "for video_batch, labels in dataloader:\n",
        "  ic(video_batch.size())\n",
        "  output = net(video_batch)\n",
        "  ic(output.size())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| video_batch.size(): torch.Size([2, 18, 3, 224, 224])\n",
            "ic| input.size(): torch.Size([2, 18, 3, 224, 224])\n",
            "ic| cnn_input.size(): torch.Size([36, 3, 224, 224])\n",
            "ic| cnn_output.size(): torch.Size([36, 2048, 1, 1])\n",
            "ic| gru_input.size(): torch.Size([2, 18, 2048])\n",
            "ic| gru_output.size(): torch.Size([2, 18, 3])\n",
            "    h_n.size(): torch.Size([1, 2, 3])\n",
            "ic| output.size(): torch.Size([2, 18, 3])\n",
            "ic| video_batch.size(): torch.Size([2, 18, 3, 224, 224])\n",
            "ic| input.size(): torch.Size([2, 18, 3, 224, 224])\n",
            "ic| cnn_input.size(): torch.Size([36, 3, 224, 224])\n",
            "ic| cnn_output.size(): torch.Size([36, 2048, 1, 1])\n",
            "ic| gru_input.size(): torch.Size([2, 18, 2048])\n",
            "ic| gru_output.size(): torch.Size([2, 18, 3])\n",
            "    h_n.size(): torch.Size([1, 2, 3])\n",
            "ic| output.size(): torch.Size([2, 18, 3])\n",
            "ic| input.size(): torch.Size([2, 18, 3, 224, 224])\n",
            "ic| cnn_input.size(): torch.Size([36, 3, 224, 224])\n",
            "ic| cnn_output.size(): torch.Size([36, 2048, 1, 1])\n",
            "ic| gru_input.size(): torch.Size([2, 18, 2048])\n",
            "ic| gru_output.size(): torch.Size([2, 18, 3])\n",
            "    h_n.size(): torch.Size([1, 2, 3])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "             GRU-174  [[-1, 18, 3], [-1, 2, 3]]               0\n",
            "================================================================\n",
            "Total params: 23,508,032\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 10.34\n",
            "Forward/backward pass size (MB): 286.55\n",
            "Params size (MB): 89.68\n",
            "Estimated Total Size (MB): 386.56\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rETHCG6vhzGY",
        "outputId": "3d86ee59-d8eb-4263-c5ce-eaa058a2c285"
      },
      "source": [
        "summary(net, (100, 3, 224, 224))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| input.size(): torch.Size([2, 100, 3, 224, 224])\n",
            "ic| cnn_input.size(): torch.Size([200, 3, 224, 224])\n",
            "ic| cnn_output.size(): torch.Size([200, 2048, 1, 1])\n",
            "ic| gru_input.size(): torch.Size([2, 100, 2048])\n",
            "ic| gru_output.size(): torch.Size([2, 100, 3])\n",
            "    h_n.size(): torch.Size([1, 2, 3])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "             GRU-174  [[-1, 100, 3], [-1, 2, 3]]               0\n",
            "================================================================\n",
            "Total params: 23,508,032\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 57.42\n",
            "Forward/backward pass size (MB): 286.54\n",
            "Params size (MB): 89.68\n",
            "Estimated Total Size (MB): 433.63\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}